{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from neo4j import GraphDatabase\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "NEO4J_URI=\"bolt://localhost\"\n",
    "NEO4J_USERNAME=\"neo4j\"\n",
    "NEO4J_PASSWORD=\"neo4jneo4j\"\n",
    "NEO4J_DATABASE=\"neo4j\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver = GraphDatabase.driver(NEO4J_URI, auth=(NEO4J_USERNAME, NEO4J_PASSWORD))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connection successful, returned: 1\n"
     ]
    }
   ],
   "source": [
    "def test_connection():\n",
    "    try:\n",
    "        with driver.session(database=NEO4J_DATABASE) as session:\n",
    "            result = session.run(\"RETURN 1 AS result\")\n",
    "            for record in result:\n",
    "                print(\"Connection successful, returned:\", record[\"result\"])\n",
    "    except Exception as e:\n",
    "        print(\"An error occurred:\", e)\n",
    "    finally:\n",
    "        driver.close()\n",
    "\n",
    "# Test the connection\n",
    "test_connection()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def batched_import(statement, df, batch_size=1000):\n",
    "    total = len(df)\n",
    "    start_s = time.time()\n",
    "    for start in range(0,total, batch_size):\n",
    "        batch = df.iloc[start: min(start+batch_size,total)]\n",
    "        result = driver.execute_query(\"UNWIND $rows AS value \" + statement, \n",
    "                                      rows=batch.to_dict('records'),\n",
    "                                      database_=NEO4J_DATABASE)\n",
    "        print(result.summary.counters)\n",
    "    print(f'{total} rows in { time.time() - start_s} s.')    \n",
    "    return total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "create constraint chunk_id if not exists for (c:__Chunk__) require c.id is unique\n",
      "\n",
      "create constraint document_id if not exists for (d:__Document__) require d.id is unique\n",
      "\n",
      "create constraint entity_id if not exists for (c:__Community__) require c.community is unique\n",
      "\n",
      "create constraint entity_id if not exists for (e:__Entity__) require e.id is unique\n",
      "\n",
      "create constraint entity_title if not exists for (e:__Entity__) require e.title is unique\n",
      "\n",
      "create constraint related_id if not exists for ()-[rel:RELATED]->() require rel.id is unique\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/10/x5kq9z89239_xvr447q1hc200000gp/T/ipykernel_18697/698945833.py:15: DeprecationWarning: Using a driver after it has been closed is deprecated. Future versions of the driver will raise an error.\n",
      "  driver.execute_query(query_=s,database_=NEO4J_DATABASE)\n"
     ]
    }
   ],
   "source": [
    "# create constraints\n",
    "\n",
    "statements = \"\"\"\n",
    "create constraint chunk_id if not exists for (c:__Chunk__) require c.id is unique;\n",
    "create constraint document_id if not exists for (d:__Document__) require d.id is unique;\n",
    "create constraint entity_id if not exists for (c:__Community__) require c.community is unique;\n",
    "create constraint entity_id if not exists for (e:__Entity__) require e.id is unique;\n",
    "create constraint entity_title if not exists for (e:__Entity__) require e.title is unique;\n",
    "create constraint related_id if not exists for ()-[rel:RELATED]->() require rel.id is unique;\n",
    "\"\"\".split(\";\")\n",
    "\n",
    "for s in statements:\n",
    "    if len((s or \"\").strip()) > 0:\n",
    "        print(s)\n",
    "        driver.execute_query(query_=s,database_=NEO4J_DATABASE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "GRAPHRAG_FOLDER=\"/Users/ali.shamsaddinlou/Documents/codes/grepx/mp2_visualize_cypher/output/20240713-191603/artifacts\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>level</th>\n",
       "      <th>clustered_graph</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>&lt;graphml xmlns=\"http://graphml.graphdrawing.or...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>&lt;graphml xmlns=\"http://graphml.graphdrawing.or...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>&lt;graphml xmlns=\"http://graphml.graphdrawing.or...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   level                                    clustered_graph\n",
       "0      0  <graphml xmlns=\"http://graphml.graphdrawing.or...\n",
       "1      1  <graphml xmlns=\"http://graphml.graphdrawing.or...\n",
       "2      2  <graphml xmlns=\"http://graphml.graphdrawing.or..."
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_parquet(f'{GRAPHRAG_FOLDER}/create_base_entity_graph.parquet')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/10/x5kq9z89239_xvr447q1hc200000gp/T/ipykernel_18697/1511357600.py:6: DeprecationWarning: Using a driver after it has been closed is deprecated. Future versions of the driver will raise an error.\n",
      "  result = driver.execute_query(\"UNWIND $rows AS value \" + statement,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'_contains_updates': True, 'properties_set': 1}\n",
      "1 rows in 0.20817804336547852 s.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2cf4ed21ae475daaed3652a148d1852d</td>\n",
       "      <td>book.txt</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 id     title\n",
       "0  2cf4ed21ae475daaed3652a148d1852d  book.txt"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import documents\n",
    "statement = \"\"\"\n",
    "MERGE (d:__Document__ {id:value.id})\n",
    "SET d += value {.title}\n",
    "// , text_unit_ids:value.text_unit_ids, raw_content:substring(value.raw_content,0,1000)};\n",
    "\"\"\"\n",
    "df = pd.read_parquet(f'{GRAPHRAG_FOLDER}/create_final_documents.parquet', columns=[\"id\", \"title\"])\n",
    "\n",
    "batched_import(statement, df)\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'_contains_updates': True, 'properties_set': 446}\n",
      "223 rows in 0.15477299690246582 s.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/10/x5kq9z89239_xvr447q1hc200000gp/T/ipykernel_18697/1511357600.py:6: DeprecationWarning: Using a driver after it has been closed is deprecated. Future versions of the driver will raise an error.\n",
      "  result = driver.execute_query(\"UNWIND $rows AS value \" + statement,\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>chunk_id</th>\n",
       "      <th>chunk</th>\n",
       "      <th>n_tokens</th>\n",
       "      <th>document_ids</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>35de79706475f0a65cb4adaaab71526d</td>\n",
       "      <td>﻿The Project Gutenberg EBook of A Christmas Ca...</td>\n",
       "      <td>300</td>\n",
       "      <td>[2cf4ed21ae475daaed3652a148d1852d]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8f08fadf9653400d20c5cf30e84da83b</td>\n",
       "      <td>which shall not put my\\nreaders out of humour...</td>\n",
       "      <td>300</td>\n",
       "      <td>[2cf4ed21ae475daaed3652a148d1852d]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           chunk_id  \\\n",
       "0  35de79706475f0a65cb4adaaab71526d   \n",
       "1  8f08fadf9653400d20c5cf30e84da83b   \n",
       "\n",
       "                                               chunk  n_tokens  \\\n",
       "0  ﻿The Project Gutenberg EBook of A Christmas Ca...       300   \n",
       "1   which shall not put my\\nreaders out of humour...       300   \n",
       "\n",
       "                         document_ids  \n",
       "0  [2cf4ed21ae475daaed3652a148d1852d]  \n",
       "1  [2cf4ed21ae475daaed3652a148d1852d]  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import text units\n",
    "statement = \"\"\"\n",
    "MERGE (c:__Chunk__ {id:value.chunk_id})\n",
    "SET c += value {.chunk, .n_tokens}\n",
    "WITH *\n",
    "UNWIND value.document_ids as doc_id\n",
    "MATCH (d:__Document__ {id:doc_id})\n",
    "MERGE (d)<-[:PART_OF]-(c)\n",
    "RETURN count(distinct c) as chunksCreated\n",
    "\"\"\"\n",
    "\n",
    "df = pd.read_parquet(f'{GRAPHRAG_FOLDER}/create_base_text_units.parquet', \n",
    "                     columns=[\"chunk_id\",\"chunk\",\"n_tokens\",\"document_ids\"])\n",
    "\n",
    "batched_import(statement, df)\n",
    "\n",
    "df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/10/x5kq9z89239_xvr447q1hc200000gp/T/ipykernel_18697/1511357600.py:6: DeprecationWarning: Using a driver after it has been closed is deprecated. Future versions of the driver will raise an error.\n",
      "  result = driver.execute_query(\"UNWIND $rows AS value \" + statement,\n"
     ]
    },
    {
     "ename": "ClientError",
     "evalue": "{code: Neo.ClientError.Procedure.ProcedureCallFailed} {message: Failed to invoke function `apoc.text.upperCamelCase`: Caused by: java.lang.StringIndexOutOfBoundsException: Range [0, 1) out of bounds for length 0}",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mClientError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[17], line 17\u001b[0m\n\u001b[1;32m      3\u001b[0m statement \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\"\"\u001b[39m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;124mMERGE (n:__Entity__ \u001b[39m\u001b[38;5;124m{\u001b[39m\u001b[38;5;124mid:value.id})\u001b[39m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;124mSET n += value \u001b[39m\u001b[38;5;124m{\u001b[39m\u001b[38;5;124m.level, .top_level_node_id, .human_readable_id, .description, \u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;124mRETURN count(distinct n) as createdNodes\u001b[39m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;124m\"\"\"\u001b[39m\n\u001b[1;32m     14\u001b[0m df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_parquet(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mGRAPHRAG_FOLDER\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/create_final_nodes.parquet\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m     15\u001b[0m                      columns\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlevel\u001b[39m\u001b[38;5;124m\"\u001b[39m,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtitle\u001b[39m\u001b[38;5;124m\"\u001b[39m,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtype\u001b[39m\u001b[38;5;124m\"\u001b[39m,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdescription\u001b[39m\u001b[38;5;124m\"\u001b[39m,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msource_id\u001b[39m\u001b[38;5;124m\"\u001b[39m,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhuman_readable_id\u001b[39m\u001b[38;5;124m\"\u001b[39m,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mid\u001b[39m\u001b[38;5;124m\"\u001b[39m,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtop_level_node_id\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[0;32m---> 17\u001b[0m \u001b[43mbatched_import\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstatement\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdf\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     18\u001b[0m df\u001b[38;5;241m.\u001b[39mhead(\u001b[38;5;241m2\u001b[39m)\n",
      "Cell \u001b[0;32mIn[9], line 6\u001b[0m, in \u001b[0;36mbatched_import\u001b[0;34m(statement, df, batch_size)\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m start \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m0\u001b[39m,total, batch_size):\n\u001b[1;32m      5\u001b[0m     batch \u001b[38;5;241m=\u001b[39m df\u001b[38;5;241m.\u001b[39miloc[start: \u001b[38;5;28mmin\u001b[39m(start\u001b[38;5;241m+\u001b[39mbatch_size,total)]\n\u001b[0;32m----> 6\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mdriver\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute_query\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mUNWIND $rows AS value \u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mstatement\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43m                                  \u001b[49m\u001b[43mrows\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_dict\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mrecords\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[43m                                  \u001b[49m\u001b[43mdatabase_\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mNEO4J_DATABASE\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      9\u001b[0m     \u001b[38;5;28mprint\u001b[39m(result\u001b[38;5;241m.\u001b[39msummary\u001b[38;5;241m.\u001b[39mcounters)\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtotal\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m rows in \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;250m \u001b[39mtime\u001b[38;5;241m.\u001b[39mtime()\u001b[38;5;250m \u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;250m \u001b[39mstart_s\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m s.\u001b[39m\u001b[38;5;124m'\u001b[39m)    \n",
      "File \u001b[0;32m~/Documents/codes/grepx/.venv/lib/python3.10/site-packages/neo4j/_sync/driver.py:959\u001b[0m, in \u001b[0;36mDriver.execute_query\u001b[0;34m(self, query_, parameters_, routing_, database_, impersonated_user_, bookmark_manager_, auth_, result_transformer_, **kwargs)\u001b[0m\n\u001b[1;32m    956\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInvalid routing control value: \u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    957\u001b[0m                      \u001b[38;5;241m%\u001b[39m routing_)\n\u001b[1;32m    958\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m session\u001b[38;5;241m.\u001b[39m_pipelined_begin:\n\u001b[0;32m--> 959\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43msession\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run_transaction\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    960\u001b[0m \u001b[43m        \u001b[49m\u001b[43maccess_mode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mTelemetryAPI\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mDRIVER\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    961\u001b[0m \u001b[43m        \u001b[49m\u001b[43mwork\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mquery_str\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparameters\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mresult_transformer_\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\u001b[43m}\u001b[49m\n\u001b[1;32m    962\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/codes/grepx/.venv/lib/python3.10/site-packages/neo4j/_sync/work/session.py:554\u001b[0m, in \u001b[0;36mSession._run_transaction\u001b[0;34m(self, access_mode, api, transaction_function, args, kwargs)\u001b[0m\n\u001b[1;32m    552\u001b[0m tx \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_transaction\n\u001b[1;32m    553\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 554\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mtransaction_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    555\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m asyncio\u001b[38;5;241m.\u001b[39mCancelledError:\n\u001b[1;32m    556\u001b[0m     \u001b[38;5;66;03m# if cancellation callback has not been called yet:\u001b[39;00m\n\u001b[1;32m    557\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_transaction \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/Documents/codes/grepx/.venv/lib/python3.10/site-packages/neo4j/_sync/driver.py:1291\u001b[0m, in \u001b[0;36m_work\u001b[0;34m(tx, query, parameters, transformer)\u001b[0m\n\u001b[1;32m   1284\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_work\u001b[39m(\n\u001b[1;32m   1285\u001b[0m     tx: ManagedTransaction,\n\u001b[1;32m   1286\u001b[0m     query: te\u001b[38;5;241m.\u001b[39mLiteralString,\n\u001b[1;32m   1287\u001b[0m     parameters: t\u001b[38;5;241m.\u001b[39mDict[\u001b[38;5;28mstr\u001b[39m, t\u001b[38;5;241m.\u001b[39mAny],\n\u001b[1;32m   1288\u001b[0m     transformer: t\u001b[38;5;241m.\u001b[39mCallable[[Result], t\u001b[38;5;241m.\u001b[39mUnion[_T]]\n\u001b[1;32m   1289\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m _T:\n\u001b[1;32m   1290\u001b[0m     res \u001b[38;5;241m=\u001b[39m tx\u001b[38;5;241m.\u001b[39mrun(query, parameters)\n\u001b[0;32m-> 1291\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtransformer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mres\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/codes/grepx/.venv/lib/python3.10/site-packages/neo4j/_sync/work/result.py:772\u001b[0m, in \u001b[0;36mResult.to_eager_result\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    754\u001b[0m \u001b[38;5;129m@NonConcurrentMethodChecker\u001b[39m\u001b[38;5;241m.\u001b[39mnon_concurrent_method\n\u001b[1;32m    755\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mto_eager_result\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m EagerResult:\n\u001b[1;32m    756\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Convert this result to an :class:`.EagerResult`.\u001b[39;00m\n\u001b[1;32m    757\u001b[0m \n\u001b[1;32m    758\u001b[0m \u001b[38;5;124;03m    This method exhausts the result and triggers a :meth:`.consume`.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    769\u001b[0m \u001b[38;5;124;03m    .. versionchanged:: 5.8 Stabilized from experimental.\u001b[39;00m\n\u001b[1;32m    770\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 772\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_buffer_all\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    773\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m EagerResult(\n\u001b[1;32m    774\u001b[0m         keys\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mkeys()),\n\u001b[1;32m    775\u001b[0m         records\u001b[38;5;241m=\u001b[39mUtil\u001b[38;5;241m.\u001b[39mlist(\u001b[38;5;28mself\u001b[39m),\n\u001b[1;32m    776\u001b[0m         summary\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconsume()\n\u001b[1;32m    777\u001b[0m     )\n",
      "File \u001b[0;32m~/Documents/codes/grepx/.venv/lib/python3.10/site-packages/neo4j/_sync/work/result.py:440\u001b[0m, in \u001b[0;36mResult._buffer_all\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    436\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_buffer_all\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    437\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Sets the Result object in an detached state by fetching all records\u001b[39;00m\n\u001b[1;32m    438\u001b[0m \u001b[38;5;124;03m    from the connection to the buffer.\u001b[39;00m\n\u001b[1;32m    439\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 440\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_buffer\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/codes/grepx/.venv/lib/python3.10/site-packages/neo4j/_sync/work/result.py:426\u001b[0m, in \u001b[0;36mResult._buffer\u001b[0;34m(self, n)\u001b[0m\n\u001b[1;32m    424\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[1;32m    425\u001b[0m record_buffer \u001b[38;5;241m=\u001b[39m deque()\n\u001b[0;32m--> 426\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m record \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[1;32m    427\u001b[0m     record_buffer\u001b[38;5;241m.\u001b[39mappend(record)\n\u001b[1;32m    428\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m n \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(record_buffer) \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m n:\n",
      "File \u001b[0;32m~/Documents/codes/grepx/.venv/lib/python3.10/site-packages/neo4j/_sync/work/result.py:378\u001b[0m, in \u001b[0;36mResult.__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    376\u001b[0m     \u001b[38;5;28;01myield\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_record_buffer\u001b[38;5;241m.\u001b[39mpopleft()\n\u001b[1;32m    377\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_streaming:\n\u001b[0;32m--> 378\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_connection\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfetch_message\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    379\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_discarding:\n\u001b[1;32m    380\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_discard()\n",
      "File \u001b[0;32m~/Documents/codes/grepx/.venv/lib/python3.10/site-packages/neo4j/_sync/io/_common.py:178\u001b[0m, in \u001b[0;36mConnectionErrorHandler.__getattr__.<locals>.outer.<locals>.inner\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    176\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21minner\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    177\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 178\u001b[0m         \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    179\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m (Neo4jError, ServiceUnavailable, SessionExpired) \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[1;32m    180\u001b[0m         \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m asyncio\u001b[38;5;241m.\u001b[39miscoroutinefunction(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__on_error)\n",
      "File \u001b[0;32m~/Documents/codes/grepx/.venv/lib/python3.10/site-packages/neo4j/_sync/io/_bolt.py:855\u001b[0m, in \u001b[0;36mBolt.fetch_message\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    851\u001b[0m \u001b[38;5;66;03m# Receive exactly one message\u001b[39;00m\n\u001b[1;32m    852\u001b[0m tag, fields \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minbox\u001b[38;5;241m.\u001b[39mpop(\n\u001b[1;32m    853\u001b[0m     hydration_hooks\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mresponses[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mhydration_hooks\n\u001b[1;32m    854\u001b[0m )\n\u001b[0;32m--> 855\u001b[0m res \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_process_message\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtag\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfields\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    856\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39midle_since \u001b[38;5;241m=\u001b[39m monotonic()\n\u001b[1;32m    857\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m res\n",
      "File \u001b[0;32m~/Documents/codes/grepx/.venv/lib/python3.10/site-packages/neo4j/_sync/io/_bolt5.py:370\u001b[0m, in \u001b[0;36mBolt5x0._process_message\u001b[0;34m(self, tag, fields)\u001b[0m\n\u001b[1;32m    368\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_server_state_manager\u001b[38;5;241m.\u001b[39mstate \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbolt_states\u001b[38;5;241m.\u001b[39mFAILED\n\u001b[1;32m    369\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 370\u001b[0m     \u001b[43mresponse\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mon_failure\u001b[49m\u001b[43m(\u001b[49m\u001b[43msummary_metadata\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    371\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (ServiceUnavailable, DatabaseUnavailable):\n\u001b[1;32m    372\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpool:\n",
      "File \u001b[0;32m~/Documents/codes/grepx/.venv/lib/python3.10/site-packages/neo4j/_sync/io/_common.py:245\u001b[0m, in \u001b[0;36mResponse.on_failure\u001b[0;34m(self, metadata)\u001b[0m\n\u001b[1;32m    243\u001b[0m handler \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandlers\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mon_summary\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    244\u001b[0m Util\u001b[38;5;241m.\u001b[39mcallback(handler)\n\u001b[0;32m--> 245\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m Neo4jError\u001b[38;5;241m.\u001b[39mhydrate(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mmetadata)\n",
      "\u001b[0;31mClientError\u001b[0m: {code: Neo.ClientError.Procedure.ProcedureCallFailed} {message: Failed to invoke function `apoc.text.upperCamelCase`: Caused by: java.lang.StringIndexOutOfBoundsException: Range [0, 1) out of bounds for length 0}"
     ]
    }
   ],
   "source": [
    "# import nodes\n",
    "\n",
    "statement = \"\"\"\n",
    "MERGE (n:__Entity__ {id:value.id})\n",
    "SET n += value {.level, .top_level_node_id, .human_readable_id, .description, \n",
    "    title:replace(value.title,'\"','')}\n",
    "WITH n, value\n",
    "CALL apoc.create.addLabels(n, case when value.type is null then [] else [apoc.text.upperCamelCase(replace(value.type,'\"',''))] end) yield node\n",
    "UNWIND split(value.source_id,\",\") as source_id\n",
    "MATCH (c:__Chunk__ {id:source_id})\n",
    "RETURN count(distinct n) as createdNodes\n",
    "\"\"\"\n",
    "\n",
    "df = pd.read_parquet(f'{GRAPHRAG_FOLDER}/create_final_nodes.parquet',\n",
    "                     columns=[\"level\",\"title\",\"type\",\"description\",\"source_id\",\"human_readable_id\",\"id\",\"top_level_node_id\"])\n",
    "\n",
    "batched_import(statement, df)\n",
    "df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{}\n",
      "177 rows in 0.15979599952697754 s.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/10/x5kq9z89239_xvr447q1hc200000gp/T/ipykernel_18697/1511357600.py:6: DeprecationWarning: Using a driver after it has been closed is deprecated. Future versions of the driver will raise an error.\n",
      "  result = driver.execute_query(\"UNWIND $rows AS value \" + statement,\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>source</th>\n",
       "      <th>target</th>\n",
       "      <th>id</th>\n",
       "      <th>rank</th>\n",
       "      <th>weight</th>\n",
       "      <th>human_readable_id</th>\n",
       "      <th>description</th>\n",
       "      <th>text_unit_ids</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>\"PROJECT GUTENBERG\"</td>\n",
       "      <td>\"A CHRISTMAS CAROL\"</td>\n",
       "      <td>66cdf168f36d4a57a505028c97dc06e0</td>\n",
       "      <td>10</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>\"Project Gutenberg provides 'A Christmas Carol...</td>\n",
       "      <td>[35de79706475f0a65cb4adaaab71526d]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>\"PROJECT GUTENBERG\"</td>\n",
       "      <td>\"PROJECT GUTENBERG-TM CONCEPT\"</td>\n",
       "      <td>38f51478f41f48db9bee570859b6f43e</td>\n",
       "      <td>9</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>\"Project Gutenberg is the organization that em...</td>\n",
       "      <td>[e5183a1390d94d0eadbb0a36992f56a6]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                source                          target  \\\n",
       "0  \"PROJECT GUTENBERG\"             \"A CHRISTMAS CAROL\"   \n",
       "1  \"PROJECT GUTENBERG\"  \"PROJECT GUTENBERG-TM CONCEPT\"   \n",
       "\n",
       "                                 id  rank  weight human_readable_id  \\\n",
       "0  66cdf168f36d4a57a505028c97dc06e0    10     1.0                 0   \n",
       "1  38f51478f41f48db9bee570859b6f43e     9     1.0                 1   \n",
       "\n",
       "                                         description  \\\n",
       "0  \"Project Gutenberg provides 'A Christmas Carol...   \n",
       "1  \"Project Gutenberg is the organization that em...   \n",
       "\n",
       "                        text_unit_ids  \n",
       "0  [35de79706475f0a65cb4adaaab71526d]  \n",
       "1  [e5183a1390d94d0eadbb0a36992f56a6]  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import relationships\n",
    "\n",
    "statement = \"\"\"\n",
    "    MATCH (source:__Entity__ {title:replace(value.source,'\"','')})\n",
    "    MATCH (target:__Entity__ {title:replace(value.target,'\"','')})\n",
    "    // todo rel-type from source-target labels?\n",
    "    MERGE (source)-[rel:RELATED]->(target)\n",
    "    SET rel += value {.id, .rank, .weight, .human_readable_id, .description, text_unit_ids:value.text_unit_ids}\n",
    "    RETURN count(*) as createdRels\n",
    "\"\"\"\n",
    "\n",
    "df = pd.read_parquet(f'{GRAPHRAG_FOLDER}/create_final_relationships.parquet',\n",
    "                     columns=[\"source\",\"target\",\"id\",\"rank\",\"weight\",\"human_readable_id\",\"description\",\"text_unit_ids\"])\n",
    "\n",
    "batched_import(statement, df)\n",
    "\n",
    "df.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/10/x5kq9z89239_xvr447q1hc200000gp/T/ipykernel_18697/1511357600.py:6: DeprecationWarning: Using a driver after it has been closed is deprecated. Future versions of the driver will raise an error.\n",
      "  result = driver.execute_query(\"UNWIND $rows AS value \" + statement,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'_contains_updates': True, 'labels_added': 24, 'nodes_created': 24, 'properties_set': 72}\n",
      "24 rows in 0.23827505111694336 s.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>level</th>\n",
       "      <th>title</th>\n",
       "      <th>text_unit_ids</th>\n",
       "      <th>relationship_ids</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Community 1</td>\n",
       "      <td>[40bb8a4f2533b792c0c0225aadd637d6,8f08fadf9653...</td>\n",
       "      <td>[35489ca6a63b47d6a8913cf333818bc1, 5d3344f45e6...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>Community 5</td>\n",
       "      <td>[05a2e2cfe5c2c70286d83aef97a10880,7c06917b335f...</td>\n",
       "      <td>[4bc7440b8f4b4e4cae65a5c49defa923, 5d1b038ce8b...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  id  level        title                                      text_unit_ids  \\\n",
       "0  1      0  Community 1  [40bb8a4f2533b792c0c0225aadd637d6,8f08fadf9653...   \n",
       "1  5      0  Community 5  [05a2e2cfe5c2c70286d83aef97a10880,7c06917b335f...   \n",
       "\n",
       "                                    relationship_ids  \n",
       "0  [35489ca6a63b47d6a8913cf333818bc1, 5d3344f45e6...  \n",
       "1  [4bc7440b8f4b4e4cae65a5c49defa923, 5d1b038ce8b...  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import communities\n",
    "\n",
    "statement = \"\"\"\n",
    "MERGE (c:__Community__ {community:value.id})\n",
    "SET c += value {.level, .title}\n",
    "/*\n",
    "UNWIND value.text_unit_ids as text_unit_id\n",
    "MATCH (t:__Chunk__ {id:text_unit_id})\n",
    "MERGE (c)-[:HAS_CHUNK]->(t)\n",
    "WITH distinct c, value\n",
    "*/\n",
    "WITH *\n",
    "UNWIND value.relationship_ids as rel_id\n",
    "MATCH (start:__Entity__)-[:RELATED {id:rel_id}]->(end:__Entity__)\n",
    "MERGE (start)-[:IN_COMMUNITY]->(c)\n",
    "MERGE (end)-[:IN_COMMUNITY]->(c)\n",
    "RETURn count(distinct c) as createdCommunities\n",
    "\"\"\"\n",
    "\n",
    "df = pd.read_parquet(f'{GRAPHRAG_FOLDER}/create_final_communities.parquet', \n",
    "                     columns=[\"id\",\"level\",\"title\",\"text_unit_ids\",\"relationship_ids\"])\n",
    "batched_import(statement, df)\n",
    "\n",
    "df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/10/x5kq9z89239_xvr447q1hc200000gp/T/ipykernel_18697/1511357600.py:6: DeprecationWarning: Using a driver after it has been closed is deprecated. Future versions of the driver will raise an error.\n",
      "  result = driver.execute_query(\"UNWIND $rows AS value \" + statement,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'_contains_updates': True, 'properties_set': 161}\n",
      "23 rows in 0.20569872856140137 s.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>community</th>\n",
       "      <th>level</th>\n",
       "      <th>title</th>\n",
       "      <th>summary</th>\n",
       "      <th>findings</th>\n",
       "      <th>rank</th>\n",
       "      <th>rank_explanation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>147a5146-691e-4827-a019-e4da22af8a27</td>\n",
       "      <td>22</td>\n",
       "      <td>2</td>\n",
       "      <td>Scrooge's Transformation and Its Impact on His...</td>\n",
       "      <td>This report delves into the profound transform...</td>\n",
       "      <td>[{'explanation': 'Ebenezer Scrooge is initiall...</td>\n",
       "      <td>8.5</td>\n",
       "      <td>The impact severity rating is high due to the ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ce2cd24e-e323-4f45-b558-3b0c46f5aeb7</td>\n",
       "      <td>23</td>\n",
       "      <td>2</td>\n",
       "      <td>The Phantom's Guiding Influence on Scrooge</td>\n",
       "      <td>This report delves into the pivotal roles of T...</td>\n",
       "      <td>[{'explanation': 'The Phantom plays a crucial ...</td>\n",
       "      <td>8.5</td>\n",
       "      <td>The impact severity rating is high due to the ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     id community  level  \\\n",
       "0  147a5146-691e-4827-a019-e4da22af8a27        22      2   \n",
       "1  ce2cd24e-e323-4f45-b558-3b0c46f5aeb7        23      2   \n",
       "\n",
       "                                               title  \\\n",
       "0  Scrooge's Transformation and Its Impact on His...   \n",
       "1         The Phantom's Guiding Influence on Scrooge   \n",
       "\n",
       "                                             summary  \\\n",
       "0  This report delves into the profound transform...   \n",
       "1  This report delves into the pivotal roles of T...   \n",
       "\n",
       "                                            findings  rank  \\\n",
       "0  [{'explanation': 'Ebenezer Scrooge is initiall...   8.5   \n",
       "1  [{'explanation': 'The Phantom plays a crucial ...   8.5   \n",
       "\n",
       "                                    rank_explanation  \n",
       "0  The impact severity rating is high due to the ...  \n",
       "1  The impact severity rating is high due to the ...  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import communities\n",
    "\n",
    "statement = \"\"\"\n",
    "MERGE (c:__Community__ {community:value.community})\n",
    "// we can also extract findings as separate nodes\n",
    "WITH c, value, [f in value.findings | apoc.text.join([k in keys(f) | k+\": \"+f[k]],',\\n')] as findings\n",
    "SET c += value {.level, .title, .summary, findings, .rank, .rank_explanation, .id}\n",
    "RETURn count(distinct c) as createdCommunities\n",
    "\"\"\"\n",
    "\n",
    "df = pd.read_parquet(f'{GRAPHRAG_FOLDER}/create_final_community_reports.parquet',\n",
    "                     columns=[\"id\",\"community\",\"level\",\"title\",\"summary\", \"findings\",\"rank\",\"rank_explanation\"])\n",
    "\n",
    "batched_import(statement, df)\n",
    "df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "/*\n",
    "cp ragtest/output/*/artifacts/*.parquet $NEO4J_HOME/import\n",
    "\n",
    "echo 'apoc.import.file.enabled=true' >> $NEO4J_HOME/conf/apoc.conf\n",
    "\n",
    "cd $NEO4J_HOME/plugins\n",
    "cp ../labs/*apoc*.jar .\n",
    "curl -OL https://github.com/neo4j-contrib/neo4j-apoc-procedures/releases/download/5.21.0/apoc-5.21.0-extended.jar\n",
    "curl -OL https://github.com/neo4j-contrib/neo4j-apoc-procedures/releases/download/5.21.0/apoc-hadoop-dependencies-5.21.0-all.jar\n",
    "cd ..\n",
    "bin/neo4j console\n",
    "*/\n",
    "\n",
    "// TODO - Load documents, text-chunks, claims, communities and connect them\n",
    "\n",
    "call apoc.load.parquet(\"create_final_nodes.parquet\") yield value\n",
    "// return keys(value), value limit 5\n",
    "return \n",
    "replace(value.type,'\"','') as type, value.id, value.level, \n",
    "replace(value.title,'\"','') as title,\n",
    "value.top_level_node_id, \n",
    "value.human_readable_id as nr,\n",
    "split(value.source_id,\",\") as sources,\n",
    "value.description \n",
    "LIMIT 5;\n",
    "\n",
    "/*\n",
    "{\n",
    "  \"source_id\": \"01e84646075b255eab0a34d872336a89,10bab8e9773ee6dfbb465bfa45794c34,28f242c45159426edb8589f5ca3c10e6,2f918cd94d1825eb5cbdc2a9d3ce094e,34c3d4a02c4a7e3b8ec57f41075aeeea,3fedcfeffb43c689a33ffa06897ad045,50160bdfa976f5b946c699722c81b412,535f6bed392a62760401b1d4f2aa5e2f,608db27bee139aaab8ded9989997d00a,680dd6d2a970a49082fa4f34bf63a34e,6968390fb201fda828835d2d1fd4e953,6ea022365de9ab0d226801de90139c8a,879b3fc36c9a2427cdb8d5d41b60e11b,972bb34ddd371530f06d006480526d3e,9e59af410db84b25757e3bf90e036f39,da3ca9f93aac15c67f6acf3cca2fc229,e8cf7d2eec5c3bcbeefc60d9f15941ed,f96b5ddf7fae853edbc4d916f66c623f\",\n",
    "  \"type\": \"\"ORGANIZATION\"\",\n",
    "  \"size\": 13,\n",
    "  \"id\": \"b45241d70f0e43fca764df95b2b81f77\",\n",
    "  \"title\": \"\"PROJECT GUTENBERG\"\",\n",
    "  \"level\": 0,\n",
    "  \"degree\": 13,\n",
    "  \"description\": \"Project Gutenberg is a pioneering organization dedicated to the free distribution of electronic works, with a focus on those not protected by U.S. copyright law. It was initiated by Professor Michael S. Hart and is supported by a network of volunteers and the Gutenberg Literary Archive Foundation. The organization's mission is to increase the number of public domain and licensed works freely distributed in machine-readable form, thereby promoting free access to literature and electronic works. Project Gutenberg owns a compilation copyright in its collection of electronic works, ensuring their accessibility while requiring compliance with specific copyright and distribution guidelines outlined in their license agreement.\n",
    "\n",
    "For over forty years, Project Gutenberg has been creating and distributing eBooks, offering a vast array of works in various formats, including 'Plain Vanilla ASCII'. Its collection includes notable titles like 'A Christmas Carol', available for free under a license that allows copying, giving away, and re-using with almost no restrictions. The organization operates globally, emphasizing copyright status and adherence to its license, which includes a system of royalty payments and refunds under certain conditions. Project Gutenberg's main search facility is accessible through its website, www.gutenberg.org, facilitating easy access to its extensive library.\n",
    "\n",
    "Project Gutenberg is committed to keeping its collection freely available for future generations, supported by donations and the efforts of its volunteer network. It promotes the creation, modification, and redistribution of eBooks, especially focusing on works that allow for free copying and distribution in the United States under specific terms. The organization is described as being focused on promoting free access to electronic works, ensuring that literature remains accessible to the public while keeping its name associated with shared works in compliance with its agreement.\",\n",
    "  \"top_level_node_id\": \"b45241d70f0e43fca764df95b2b81f77\",\n",
    "  \"human_readable_id\": 0,\n",
    "  \"__index_level_0__\": 0,\n",
    "  \"y\": 0,\n",
    "  \"x\": 0\n",
    "}\n",
    "*/\n",
    "create constraint chunk_id if not exists for (c:__Chunk__) require c.id is unique;\n",
    "create constraint document_id if not exists for (d:__Document__) require d.id is unique;\n",
    "create constraint entity_id if not exists for (c:__Community__) require c.community is unique;\n",
    "\n",
    "create constraint entity_id if not exists for (e:__Entity__) require e.id is unique;\n",
    "create constraint entity_title if not exists for (e:__Entity__) require e.title is unique;\n",
    "create constraint related_id if not exists for ()-[rel:RELATED]->() require rel.id is unique;\n",
    "\n",
    "\n",
    "call apoc.load.parquet(\"create_final_documents.parquet\") yield value\n",
    "return keys(value),value limit 1;\n",
    "\n",
    "// [\"__index_level_0__\", \"raw_content\", \"id\", \"title\", \"text_unit_ids\"]\n",
    "\n",
    "call apoc.load.parquet(\"create_final_documents.parquet\") yield value\n",
    "MERGE (d:__Document__ {id:value.id})\n",
    "SET d += value {.title, text_unit_ids:value.text_unit_ids, raw_content:substring(value.raw_content,0,1000)};\n",
    "\n",
    "call apoc.load.parquet(\"create_base_text_units.parquet\") yield value\n",
    "return keys(value),value limit 1;\n",
    "// [\"document_ids\", \"chunk\", \"n_tokens\", \"id\", \"chunk_id\"]\n",
    "\n",
    ":auto\n",
    "call apoc.load.parquet(\"create_base_text_units.parquet\") yield value\n",
    "CALL { with value \n",
    "MERGE (c:__Chunk__ {id:value.chunk_id})\n",
    "SET c += value {.chunk, .n_tokens}\n",
    "WITH *\n",
    "UNWIND value.document_ids as doc_id\n",
    "MATCH (d:__Document__ {id:doc_id})\n",
    "MERGE (d)<-[:PART_OF]-(c)\n",
    "RETURN count(distinct c) as chunksCreated\n",
    "} in transactions of 1000 rows\n",
    "RETURN sum(chunksCreated) as chunksCreated;\n",
    "\n",
    "\n",
    ":auto\n",
    "call apoc.load.parquet(\"create_final_nodes.parquet\") yield value\n",
    "call { with value\n",
    "    MERGE (n:__Entity__ {id:value.id})\n",
    "    SET n += value {.level, .top_level_node_id, .human_readable_id, .description, \n",
    "        title:replace(value.title,'\"','')}\n",
    "    WITH n, value\n",
    "    CALL apoc.create.addLabels(n, case when value.type is null then [] else [apoc.text.upperCamelCase(replace(value.type,'\"',''))] end) yield node\n",
    "    UNWIND split(value.source_id,\",\") as source_id\n",
    "    MATCH (c:__Chunk__ {id:source_id})\n",
    "    MERGE (c)-[:HAS_ENTITY]->(n)\n",
    "    RETURN count(distinct n) as created\n",
    "} in transactions of 25000 rows\n",
    "return sum(created) as createdNodes;\n",
    "\n",
    "\n",
    "call apoc.load.parquet(\"create_final_relationships.parquet\") yield value\n",
    "return keys(value), value limit 5;\n",
    "\n",
    ":auto\n",
    "call apoc.load.parquet(\"create_final_relationships.parquet\") yield value\n",
    "call { with value\n",
    "    MATCH (source:__Entity__ {title:replace(value.source,'\"','')})\n",
    "    MATCH (target:__Entity__ {title:replace(value.target,'\"','')})\n",
    "    // todo rel-type from source-target labels?\n",
    "    MERGE (source)-[rel:RELATED]->(target)\n",
    "    SET rel += value {.id, .rank, .weight, .human_readable_id, .description, text_unit_ids:value.text_unit_ids}\n",
    "    RETURN count(*) as created\n",
    "} in transactions of 25000 rows\n",
    "return sum(created) as createdRels;\n",
    "\n",
    "/*\n",
    "{\n",
    "  \"id\": \"b84d71ed9c3b45819eb3205fd28e13a0\",\n",
    "  \"target_degree\": 7,\n",
    "  \"rank\": 20,\n",
    "  \"source_degree\": 13,\n",
    "  \"weight\": 1.0,\n",
    "  \"source\": \"\"PROJECT GUTENBERG\"\",\n",
    "  \"description\": \"\"Project Gutenberg is responsible for releasing 'A Christmas Carol' as an eBook.\"\",\n",
    "  \"target\": \"\"A CHRISTMAS CAROL\"\",\n",
    "  \"human_readable_id\": \"0\",\n",
    "  \"text_unit_ids\": [\n",
    "    \"680dd6d2a970a49082fa4f34bf63a34e\"\n",
    "  ]\n",
    "}\n",
    "*/\n",
    "\n",
    ":auto\n",
    "call apoc.load.parquet(\"create_final_communities.parquet\") yield value\n",
    "// return keys(value), value limit 5;\n",
    "CALL { with value \n",
    "    MERGE (c:__Community__ {community:value.id})\n",
    "    SET c += value {.level, .title}\n",
    "    /*\n",
    "    UNWIND value.text_unit_ids as text_unit_id\n",
    "    MATCH (t:__Chunk__ {id:text_unit_id})\n",
    "    MERGE (c)-[:HAS_CHUNK]->(t)\n",
    "    WITH distinct c, value\n",
    "    */\n",
    "    WITH *\n",
    "    UNWIND value.relationship_ids as rel_id\n",
    "    MATCH (start:__Entity__)-[:RELATED {id:rel_id}]->(end:__Entity__)\n",
    "    MERGE (start)-[:IN_COMMUNITY]->(c)\n",
    "    MERGE (end)-[:IN_COMMUNITY]->(c)\n",
    "    RETURn count(distinct c) as created\n",
    "} in transactions of 1000 rows\n",
    "RETURN sum(created) as createdCommunities;\n",
    "\n",
    "// [\"level\", \"text_unit_ids\", \"relationship_ids\", \"id\", \"title\", \"raw_community\"]\t\n",
    "\n",
    ":auto\n",
    "call apoc.load.parquet(\"create_final_community_reports.parquet\") yield value\n",
    "CALL { with value \n",
    "    MERGE (c:__Community__ {community:value.community})\n",
    "    SET c += value {.level, .title, .summary, .findings, .rank, .rank_explanation, .id}\n",
    "    RETURn count(distinct c) as created\n",
    "} in transactions of 1000 rows\n",
    "RETURN sum(created) as createdReports;\n",
    "// [\"summary\", \"full_content_json\", \"level\", \"findings\", \"full_content\", \"rank\", \"id\", \"rank_explanation\", \"title\", \"community\"]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
